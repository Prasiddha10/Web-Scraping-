{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "from bs4 import BeautifulSoup\nimport requests\n\n\nurl = 'https://realpython.github.io/fake-jobs/'\nhtml = requests.get(url)\nsoup = BeautifulSoup(html.content, 'html.parser')\n\nresults = soup.find(class_='container mb-5')\nheading = results.find_all('h1', class_='title is-1')\n\n\nwith open('flatfile.txt', 'w') as file:\n    \n    [file.write(i.text) for i in heading]\n    file.write('\\n')\n\n\n    apply_links = soup.find_all('a', string='Apply')\n\n    apply_urls = [link['href'] for link in apply_links]\n\n\n    for  urlss in apply_urls:\n        link_html = requests.get(urlss)\n        link_soup = BeautifulSoup(link_html.content, 'html.parser')\n\n        link_results = link_soup.find(id='ResultsContainer')\n\n        Jobbtitle = link_results.find_all('h1', class_='title is-2')         \n        # [print(i.text) for i in Jobbtitle]\n        [file.write(i.text) for i in Jobbtitle]\n\n        Writerss = link_results.find_all('h2', class_=' subtitle is-4 company')\n        # [print(i.text) for i in Writerss]\n        [file.write(i.text) for i in Writerss]\n        file.write('\\n')\n\n\n        Jobbdescription = link_soup.find_all('p', class_= False, id=False)\n        # [print(i.text) for i in Jobbdescription]\n        [file.write(i.text) for i in Jobbdescription]\n        file.write('\\n')\n        \n        link_location = link_results.find_all('p', id=\"location\")\n        for i in link_location:\n            i.strong.extract() \n            # print(i.text.strip())\n            file.write(i.text.strip())\n            file.write('\\n')\n\n        \n        link_date = link_results.find_all('p', id=\"date\")\n        for i in link_date:\n            i.strong.extract() \n            # print(i.text.strip())\n            file.write(i.text.strip())\n            file.write('\\n')\n\n        file.write('\\n')\n        file.write('\\n')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'requests'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://realpython.github.io/fake-jobs/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m html \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}